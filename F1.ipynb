{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#install dependencies\n",
    "%pip install requests pandas \n",
    "!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'F1 dataset'\n",
      "/home/penguin/Documents/Code/F1RaceOutcomePrediction/F1 dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/penguin/Documents/Code/F1RaceOutcomePrediction/venv/lib/python3.12/site-packages/IPython/core/magics/osm.py:393: UserWarning: This is now an optional IPython functionality, using bookmarks requires you to install the `pickleshare` library.\n",
      "  bkms = self.shell.db.get('bookmarks', {})\n"
     ]
    }
   ],
   "source": [
    "#get data \n",
    "%cd F1 dataset \n",
    "circuits = pd.read_csv('circuits.csv')\n",
    "drivers = pd.read_csv('drivers.csv')\n",
    "lap_times = pd.read_csv('lap_times.csv')\n",
    "pit_stops = pd.read_csv('pit_stops.csv') \n",
    "qualifying = pd.read_csv('qualifying.csv')\n",
    "results = pd.read_csv('results.csv')\n",
    "seasons = pd.read_csv('seasons.csv')\n",
    "status = pd.read_csv('status.csv')\n",
    "\n",
    "#Explore the datasets\n",
    "datasets = {\n",
    "    \"Circuits\": circuits,\n",
    "    \"Drivers\": drivers,\n",
    "    \"Lap Times\": lap_times,\n",
    "    \"Pit Stops\": pit_stops,\n",
    "    \"Qualifying\": qualifying,\n",
    "    \"Results\": results,\n",
    "    \"Seasons\": seasons,\n",
    "    \"Status\": status\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data\n",
    "lap_times = datasets['Lap Times']\n",
    "drivers = datasets['Drivers']\n",
    "circuits = datasets['Circuits']\n",
    "\n",
    "\n",
    "#Data merging\n",
    "merged_data = lap_times.merge(drivers, on='driverId', how='inner')\n",
    "merged_data = merged_data.merge(circuits, left_on='driverId', right_on='circuitId', how='inner')\n",
    "\n",
    "#Convert lap times to seconds\n",
    "import pandas as pd\n",
    "\n",
    "def convert_to_seconds(time_str):\n",
    "    if isinstance(time_str, str):\n",
    "        minutes, seconds = time_str.split(':')\n",
    "        return int(minutes) * 60 + float(seconds)\n",
    "    return time_str\n",
    "\n",
    "# Ensure the correct column name is used\n",
    "if 'milliseconds' in merged_data.columns:\n",
    "    merged_data['lapTime'] = merged_data['milliseconds'].apply(lambda x: x / 1000)\n",
    "else:\n",
    "    raise KeyError(\"Column 'milliseconds' not found in the merged dataframe\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "#features\n",
    "categorical_features = ['driverId', 'circuitId']  \n",
    "one_hot = OneHotEncoder(sparse_output=False)  \n",
    "\n",
    "#transformer\n",
    "transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('one_hot', one_hot, categorical_features)\n",
    "    ],\n",
    "    remainder='passthrough'  #\n",
    ")\n",
    "encoded_data = transformer.fit_transform(merged_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "#define model\n",
    "class LapTimePredictor(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(LapTimePredictor, self).__init__()\n",
    "        # Define layers\n",
    "        self.fc1 = nn.Linear(input_size, 64)  \n",
    "        self.fc2 = nn.Linear(64, 32)        \n",
    "        self.fc3 = nn.Linear(32, 1)          \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))  \n",
    "        x = torch.relu(self.fc2(x))  \n",
    "        x = self.fc3(x)            \n",
    "        return x\n",
    "\n",
    "#initialize model \n",
    "input_size = X_train.shape[1] # Number of features\n",
    "model = LapTimePredictor(input_size)\n",
    "\n",
    "#loss function\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
